{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_n_samples_per_layer(l, n, desired_latency):\n",
    "    # Total number of samples and the latency constraint\n",
    "    n_total = n  # Replace with the actual total number of samples\n",
    "    latency_constraint = desired_latency  # Replace with desired latency constraint\n",
    "\n",
    "    # Objective function to minimize\n",
    "    def objective(n_vec):\n",
    "        weighted_latency = np.dot(n_vec, l) / np.sum(n_vec)\n",
    "        return (weighted_latency - latency_constraint) ** 2\n",
    "\n",
    "    # Equality constraint: sum of n_i = n_total\n",
    "    def eq_constraint(n_vec):\n",
    "        return np.sum(n_vec) - n_total\n",
    "\n",
    "    # Inequality constraints: n_i >= 0 for all i\n",
    "    def ineq_constraint(n_vec):\n",
    "        return n_vec  # This will ensure all elements are non-negative\n",
    "\n",
    "    # Set up constraints in the format required by scipy\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': eq_constraint},  # Equality constraint\n",
    "        {'type': 'ineq', 'fun': ineq_constraint}  # Inequality constraints\n",
    "    ]\n",
    "\n",
    "    # Initial guess for n_i (can be uniform distribution across layers)\n",
    "    initial_guess = np.full(len(l), n_total / len(l))\n",
    "\n",
    "    # Bounds for each n_i to ensure n_i >= 0\n",
    "    bounds = [(0, None) for _ in range(len(l))]\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    n_samples_per_layer = np.round(result.x).astype(int)\n",
    "    # Output the optimized n_i values and the objective value\n",
    "    if result.success:\n",
    "        # print(\"Optimized n values:\", n_samples_per_layer)\n",
    "        print(\"Minimum objective value:\", np.sqrt(result.fun))\n",
    "    else:\n",
    "        print(\"Optimization failed:\", result.message)\n",
    "    return n_samples_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.81, 3.62, 3.93, 4.97, 6.01, 7.16, 10.23, 9.22, 12.96, 11.38, 12.33, 13.49]\n",
      "872\n"
     ]
    }
   ],
   "source": [
    "def get_per_layer_latencies():\n",
    "    data_pl = np.load('./../plotting2_profile/saved_models/bert_base-SST-2-two_stage/entropy_0.0.npy', allow_pickle=True)\n",
    "    latencies = []\n",
    "    for i in np.arange(0, 12):\n",
    "        latencies.append(round(data_pl[4 * i + 1][i + 1] * 1000, 2))\n",
    "    return latencies, data_pl[0][1]\n",
    "latencies, n = get_per_layer_latencies()\n",
    "print(latencies)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency_to_n_samples_per_layer(latencies, n):\n",
    "    max_latency = math.ceil(max(latencies)) + 0.5\n",
    "    min_latency = round(min(latencies))\n",
    "    latency_to_n_samples_per_layer = {}\n",
    "    for desired_latency in np.arange(min_latency, max_latency, 0.5):\n",
    "        n_samples_per_layer = optimize_n_samples_per_layer(latencies, n, desired_latency)\n",
    "        print(f\"Desired latency: {desired_latency}, N samples per layer: {n_samples_per_layer}\")\n",
    "        latency_to_n_samples_per_layer[desired_latency] = tuple(n_samples_per_layer)\n",
    "    return latency_to_n_samples_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum objective value: 0.04090341739029846\n",
      "Desired latency: 2.0, N samples per layer: [761 111   0   0   0   0   0   0   0   0   0   0]\n",
      "Minimum objective value: 0.147529146112781\n",
      "Desired latency: 2.5, N samples per layer: [496 212 163   0   0   0   0   0   0   0   0   0]\n",
      "Minimum objective value: 0.04809066425733066\n",
      "Desired latency: 3.0, N samples per layer: [377 215 187  93   0   0   0   0   0   0   0   0]\n",
      "Minimum objective value: 3.119185759015153e-06\n",
      "Desired latency: 3.5, N samples per layer: [292 196 180 125  70   9   0   0   0   0   0   0]\n",
      "Minimum objective value: 9.587974814095901e-08\n",
      "Desired latency: 4.0, N samples per layer: [227 173 164 133 102  67   0   6   0   0   0   0]\n",
      "Minimum objective value: 1.331852583774662e-08\n",
      "Desired latency: 4.5, N samples per layer: [192 155 149 127 106  82  19  40   0   0   0   0]\n",
      "Minimum objective value: 1.7142029129502134e-08\n",
      "Desired latency: 5.0, N samples per layer: [169 141 136 120 104  86  38  54   0  20   5   0]\n",
      "Minimum objective value: 5.930297325207334e-06\n",
      "Desired latency: 5.5, N samples per layer: [152 129 125 112  99  84  46  58  11  31  19   5]\n",
      "Minimum objective value: 2.3430099583165998e-05\n",
      "Desired latency: 6.0, N samples per layer: [137 118 115 104  94  82  51  61  23  39  30  18]\n",
      "Minimum objective value: 2.2420957117574858e-06\n",
      "Desired latency: 6.5, N samples per layer: [121 107 105  97  89  80  56  64  35  47  40  31]\n",
      "Minimum objective value: 2.771043935645423e-06\n",
      "Desired latency: 7.0, N samples per layer: [106  96  95  89  84  78  61  67  47  55  50  44]\n",
      "Minimum objective value: 1.8871125142538858e-06\n",
      "Desired latency: 7.5, N samples per layer: [91 86 85 82 79 75 67 69 59 63 60 57]\n",
      "Minimum objective value: 9.80759597979386e-08\n",
      "Desired latency: 8.0, N samples per layer: [75 75 75 74 74 73 72 72 70 71 71 70]\n",
      "Minimum objective value: 2.8856899216833654e-06\n",
      "Desired latency: 8.5, N samples per layer: [60 64 64 66 69 71 77 75 82 79 81 83]\n",
      "Minimum objective value: 5.850970845600045e-06\n",
      "Desired latency: 9.0, N samples per layer: [45 53 54 59 63 69 82 78 94 87 91 97]\n",
      "Minimum objective value: 2.2493922012145617e-05\n",
      "Desired latency: 9.5, N samples per layer: [ 30  42  44  51  58  66  87  80 106  95 102 110]\n",
      "Minimum objective value: 2.7958619922330286e-05\n",
      "Desired latency: 10.0, N samples per layer: [ 14  31  34  44  53  64  93  83 118 103 112 123]\n",
      "Minimum objective value: 6.285690190566129e-09\n",
      "Desired latency: 10.5, N samples per layer: [  0  20  24  36  48  62  98  86 130 111 122 136]\n",
      "Minimum objective value: 1.1187244552957054e-07\n",
      "Desired latency: 11.0, N samples per layer: [  0   4   8  24  40  57 103  88 144 120 134 152]\n",
      "Minimum objective value: 9.801370826068023e-07\n",
      "Desired latency: 11.5, N samples per layer: [  0   0   0   3  23  46 106  86 160 129 148 170]\n",
      "Minimum objective value: 4.0088336206167696e-07\n",
      "Desired latency: 12.0, N samples per layer: [  0   0   0   0   0  12 103  73 184 137 165 199]\n",
      "Minimum objective value: 2.7842583492088124e-06\n",
      "Desired latency: 12.5, N samples per layer: [  0   0   0   0   0   0  66   8 224 133 187 255]\n",
      "Minimum objective value: 0.1928455290836375\n",
      "Desired latency: 13.0, N samples per layer: [  0   0   0   0   0   0   0   0 258 109 198 308]\n",
      "Minimum objective value: 0.427972981922764\n",
      "Desired latency: 13.5, N samples per layer: [  0   0   0   0   0   0   0   0 297   0 179 397]\n",
      "Minimum objective value: 0.6965386878321578\n",
      "Desired latency: 14.0, N samples per layer: [  0   0   0   0   0   0   0   0 307   0   0 565]\n"
     ]
    }
   ],
   "source": [
    "latency_to_n_samples_per_layer = get_latency_to_n_samples_per_layer(latencies, n)\n",
    "np.save(\"./../plotting2_profile/saved_models/bert_base-SST-2-two_stage/lat_n_samples_pl.npy\", latency_to_n_samples_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(latency_to_n_samples_per_layer))\n",
    "unique_lton = set()\n",
    "for l in latency_to_n_samples_per_layer:\n",
    "    unique_lton.add(latency_to_n_samples_per_layer[l])\n",
    "print(len(unique_lton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5]\n",
      "[8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0]\n"
     ]
    }
   ],
   "source": [
    "latencies = [float(x) for x in latency_to_n_samples_per_layer]\n",
    "print(latencies[0:12])\n",
    "print(latencies[12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 107, 2: 118, 3: 93, 4: 84, 5: 39, 6: 68, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 363}\n",
      " {1: 0.001680842069821937, 2: 0.0027254698640209133, 3: 0.003777606512910576, 4: 0.004817437557947068, 5: 0.0058552301847017724, 6: 0.006891341770396513, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0.013220137472651878}\n",
      " 0.5654625382262997\n",
      " {1: np.float64(0.9158878504672897), 2: np.float64(0.923728813559322), 12: np.float64(0.8760330578512396), 6: np.float64(0.9558823529411765), 3: np.float64(0.978494623655914), 4: np.float64(0.8571428571428571), 5: np.float64(0.8974358974358975)}]\n",
      "0.0077446248006383216\n",
      "0.9036697247706422\n"
     ]
    }
   ],
   "source": [
    "temp_data = np.load('./../plotting2_profile/saved_models/bert_base-SST-2-two_stage/lat_entropies_4.0.npy', allow_pickle=True)\n",
    "print(temp_data)\n",
    "\n",
    "total_latency = 0\n",
    "total_accuracy = 0\n",
    "for layer in range(1, 13):\n",
    "    total_latency += temp_data[0][layer] * temp_data[1][layer]\n",
    "    if layer in temp_data[3]:\n",
    "        total_accuracy += temp_data[0][layer] * temp_data[3][layer]\n",
    "total_latency /= 872\n",
    "total_accuracy /= 872\n",
    "print(total_latency)\n",
    "print(total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(227),\n",
       " np.int64(173),\n",
       " np.int64(164),\n",
       " np.int64(133),\n",
       " np.int64(102),\n",
       " np.int64(67),\n",
       " np.int64(0),\n",
       " np.int64(6),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_to_n_samples_per_layer[4.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deebert-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
